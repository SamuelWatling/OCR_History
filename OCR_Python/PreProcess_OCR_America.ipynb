{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d96ca7c",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In this notebook, we use Amazon Textract and Google Vision to provide a quick way of extracting text/tables from an image of a page.\n",
    "\n",
    "Intended use: The intended use of this notebook is to quickly prototype. You should expect to modify the code in this notebook to suit your usecase.\n",
    "\n",
    "Preparation: At a minimum, set a working folder, and make sure to add your API keys for both Textract and Google Vision. To do so, please follow the steps outlined here: https://github.com/MikeJGiordano/OCR_History/blob/main/ReadMe.md\n",
    "\n",
    "This notebook contains four parts:\n",
    "\n",
    "    1. Unmodified image OCR. This is intended to quickly detect text from a single image.\n",
    "        a. There is then an option to run one or both OCR tools on a whole folder.\n",
    "        \n",
    "    2. Image preprocessing. This routine helps you to quickly preprocess a single image (adjust contrast, split image, etc). \n",
    "        a. If you are satisfied with the preprocessing routine, it will give you the option to preprocess a whole folder.\n",
    "        \n",
    "    3. Image preprocessing with text extraction. This runs the image modification from part 2 into the text detection from part 1.\n",
    "    \n",
    "    4. Image preprocessing with table extraction from Textract. This uses the image modification from part 2 to extract a table using Textract."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17f3fe1",
   "metadata": {},
   "source": [
    "# Program Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2655be",
   "metadata": {},
   "source": [
    "## There are 5 steps, marked A-E."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c497df2",
   "metadata": {},
   "source": [
    "### A: Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af15c6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import json\n",
    "import os\n",
    "\n",
    "# if you don't have these packages use any package manager to install\n",
    "# you can install all packages at once using the provided requirements.txt file\n",
    "import cv2\n",
    "import boto3\n",
    "from google.cloud import vision\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm as tq\n",
    "\n",
    "from PIL import Image, ImageDraw\n",
    "from textractor import Textractor\n",
    "from textractor.visualizers.entitylist import EntityList\n",
    "from textractor.data.constants import TextractFeatures, Direction, DirectionalFinderType\n",
    "import math \n",
    "\n",
    "# note: the following py file, you'll have to download\n",
    "import preprocess as pp \n",
    "import logging\n",
    "import sys\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "                   format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Disable PIL max image size limit\n",
    "Image.MAX_IMAGE_PIXELS = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7098cf",
   "metadata": {},
   "source": [
    "### B: Please set your working directories here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c02996d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# please set the path to the folder containing your images here\n",
    "input_folder = \"/mnt/c/Users/WATLINGS/Documents/OCR Files/Census Processing/Documents/1920/Output\"\n",
    "output_folder = \"/mnt/c/Users/WATLINGS/Documents/OCR Files/Census Processing/Documents/1920/Output_OCR\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9adfe73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Authenticate Google Cloud here\n",
    "\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = '/mnt/c/Users/WATLINGS/Documents/GitHub/OCR_History/OCR_Python/ServiceAccountToken.json'\n",
    "client = vision.ImageAnnotatorClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a658deca",
   "metadata": {},
   "source": [
    "### E: Please authenticate Amazon Textract\n",
    "\n",
    "For help with Amazon Textract, see https://github.com/MikeJGiordano/OCR_History/blob/main/Setup_AWS_Root.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6044585",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Authenticate AWS Textract in the console/terminal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4334c36",
   "metadata": {},
   "source": [
    "# Part 1: Basic text extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c99c29a-b52e-4994-8604-d58572d83c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def resize_image_if_needed(img, max_size=8000, quality=85):\n",
    "    \"\"\"\n",
    "    Resize image if either dimension exceeds max_size while maintaining aspect ratio.\n",
    "    Added memory-efficient handling of large images.\n",
    "    \"\"\"\n",
    "    width, height = img.size\n",
    "    logger.info(f\"Processing image of size {width}x{height}\")\n",
    "    \n",
    "    if width > max_size or height > max_size:\n",
    "        # Calculate new dimensions\n",
    "        scale = max_size / max(width, height)\n",
    "        new_width = math.floor(width * scale)\n",
    "        new_height = math.floor(height * scale)\n",
    "        \n",
    "        try:\n",
    "            logger.info(f\"Resizing image from {width}x{height} to {new_width}x{new_height}\")\n",
    "            \n",
    "            # Use LANCZOS for better quality, but fall back to NEAREST if memory error\n",
    "            try:\n",
    "                img = img.resize((new_width, new_height), Image.LANCZOS)\n",
    "            except MemoryError:\n",
    "                logger.warning(\"Memory error with LANCZOS, falling back to NEAREST\")\n",
    "                img = img.resize((new_width, new_height), Image.NEAREST)\n",
    "            \n",
    "            logger.info(\"Resize successful\")\n",
    "            \n",
    "            # Convert to RGB if needed\n",
    "            if img.mode != 'RGB':\n",
    "                img = img.convert('RGB')\n",
    "                logger.info(\"Converted to RGB mode\")\n",
    "            \n",
    "            # Optimize memory usage\n",
    "            if max(new_width, new_height) > 4000:\n",
    "                # For very large images, compress more aggressively\n",
    "                quality = min(quality, 75)\n",
    "                logger.info(f\"Large image detected, using reduced quality: {quality}\")\n",
    "            \n",
    "            return img\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error during resize: {str(e)}\")\n",
    "            raise\n",
    "    \n",
    "    return img\n",
    "\n",
    "# First, let's create a function to process images and save results\n",
    "def process_and_save_text(input_folder, output_folder, filename):\n",
    "    print(f\"\\nProcessing {filename}...\")\n",
    "    \n",
    "    # Setup paths\n",
    "    input_path = os.path.join(input_folder, filename)\n",
    "    base_name = os.path.splitext(filename)[0]\n",
    "    output_text = os.path.join(output_folder, f\"{base_name}_Textract.txt\")\n",
    "    output_json = os.path.join(output_folder, f\"{base_name}_Textract.json\")\n",
    "    \n",
    "    try:\n",
    "        # Process image\n",
    "        with Image.open(input_path) as img:\n",
    "            # Resize if needed\n",
    "            img = resize_image_if_needed(img)\n",
    "            # Convert to RGB mode if needed\n",
    "            if img.mode != 'RGB':\n",
    "                img = img.convert('RGB')\n",
    "            # Save as JPEG in memory\n",
    "            buffer = io.BytesIO()\n",
    "            img.save(buffer, format='JPEG', quality=95)\n",
    "            image_content = buffer.getvalue()\n",
    "        \n",
    "        # Process with Textract\n",
    "        textract = boto3.client('textract')\n",
    "        response = textract.detect_document_text(\n",
    "            Document={'Bytes': image_content}\n",
    "        )\n",
    "        \n",
    "        # Save JSON response\n",
    "        with open(output_json, 'w', encoding='utf-8') as f:\n",
    "            json.dump(response, f, indent=2)\n",
    "            \n",
    "        # Save extracted text\n",
    "        with open(output_text, 'w', encoding='utf-8') as f:\n",
    "            for block in response['Blocks']:\n",
    "                if block['BlockType'] == 'LINE':\n",
    "                    f.write(block.get('Text', '') + '\\n')\n",
    "        \n",
    "        print(f\"Successfully processed {filename}\")\n",
    "        print(f\"Text saved to: {output_text}\")\n",
    "        print(f\"JSON saved to: {output_json}\")\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {filename}: {e}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42bdc2f2",
   "metadata": {},
   "source": [
    "# Part 4: Textract Table Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce277761",
   "metadata": {},
   "source": [
    "## Extract the tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a1dddf6-46fb-4b0a-bc77-a3f2329dcd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import math\n",
    "import io\n",
    "from tqdm import tqdm \n",
    "\n",
    "def process_image(input_path, max_size=8000):\n",
    "    \"\"\"Process a single image with enhanced error handling and memory management\"\"\"\n",
    "    try:\n",
    "        logger.info(f\"Opening image: {input_path}\")\n",
    "        \n",
    "        # Open image with lazy loading\n",
    "        with Image.open(input_path) as img:\n",
    "            # Get original size\n",
    "            orig_size = img.size\n",
    "            logger.info(f\"Original image size: {orig_size}, Mode: {img.mode}\")\n",
    "            \n",
    "            # Resize if needed\n",
    "            img = resize_image_if_needed(img, max_size)\n",
    "            \n",
    "            # Convert to RGB if needed\n",
    "            if img.mode != 'RGB':\n",
    "                img = img.convert('RGB')\n",
    "            \n",
    "            # Save as JPEG in memory with appropriate quality\n",
    "            buffer = io.BytesIO()\n",
    "            quality = 85 if max(img.size) <= 4000 else 75\n",
    "            img.save(buffer, format='JPEG', quality=quality, optimize=True)\n",
    "            \n",
    "            logger.info(f\"Successfully processed image. Original size: {orig_size}, Final size: {img.size}\")\n",
    "            return buffer.getvalue()\n",
    "            \n",
    "    except MemoryError:\n",
    "        logger.error(f\"Memory error processing {input_path}. Try reducing max_size parameter.\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error processing image {input_path}: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "def batch_resize_and_extract(extractor, input_folder, output_folder, max_size=4000):\n",
    "    \"\"\"Process all images in a folder with enhanced error handling\"\"\"\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    \n",
    "    # Get list of image files\n",
    "    valid_extensions = ['.jpg', '.jpeg', '.png', '.gif', '.tiff', '.bmp']\n",
    "    image_files = [f for f in os.listdir(input_folder) \n",
    "                  if any(f.lower().endswith(ext) for ext in valid_extensions)]\n",
    "    \n",
    "    if not image_files:\n",
    "        logger.warning(f\"No image files found in {input_folder}\")\n",
    "        return\n",
    "    \n",
    "    logger.info(f\"\\nProcessing {len(image_files)} images...\")\n",
    "    \n",
    "    successful = []\n",
    "    failed = []\n",
    "    tables_found = 0\n",
    "    \n",
    "    for filename in tqdm(image_files, desc=\"Processing images\"):\n",
    "        try:\n",
    "            # Process image first\n",
    "            input_path = os.path.join(input_folder, filename)\n",
    "            \n",
    "            with Image.open(input_path) as img:\n",
    "                # Resize if needed\n",
    "                img = resize_image_if_needed(img, max_size)\n",
    "                \n",
    "                # Convert to RGB if needed\n",
    "                if img.mode != 'RGB':\n",
    "                    img = img.convert('RGB')\n",
    "                \n",
    "                # Save directly to bytes\n",
    "                buffer = io.BytesIO()\n",
    "                img.save(buffer, format='JPEG', quality=85)\n",
    "                image_bytes = buffer.getvalue()\n",
    "            \n",
    "            # Extract tables using Textract directly\n",
    "            textract_client = boto3.client('textract')\n",
    "            response = textract_client.analyze_document(\n",
    "                Document={'Bytes': image_bytes},\n",
    "                FeatureTypes=['TABLES']\n",
    "            )\n",
    "            \n",
    "            # Process tables from response\n",
    "            if 'Blocks' in response:\n",
    "                # Find table blocks\n",
    "                table_blocks = [block for block in response['Blocks'] \n",
    "                              if block['BlockType'] == 'TABLE']\n",
    "                \n",
    "                tables_found += len(table_blocks)\n",
    "                \n",
    "                if table_blocks:\n",
    "                    # Process each table\n",
    "                    for i, table_block in enumerate(table_blocks):\n",
    "                        # Extract cells for this table\n",
    "                        cells = [block for block in response['Blocks'] \n",
    "                               if block['BlockType'] == 'CELL' and \n",
    "                               block.get('TableId') == table_block['Id']]\n",
    "                        \n",
    "                        # Convert to DataFrame\n",
    "                        table_data = []\n",
    "                        max_row = max(cell['RowIndex'] for cell in cells)\n",
    "                        max_col = max(cell['ColumnIndex'] for cell in cells)\n",
    "                        \n",
    "                        # Initialize empty table\n",
    "                        table_data = [['' for _ in range(max_col)] for _ in range(max_row)]\n",
    "                        \n",
    "                        # Fill in cell values\n",
    "                        for cell in cells:\n",
    "                            row_idx = cell['RowIndex'] - 1\n",
    "                            col_idx = cell['ColumnIndex'] - 1\n",
    "                            if 'Text' in cell:\n",
    "                                table_data[row_idx][col_idx] = cell['Text']\n",
    "                        \n",
    "                        # Convert to DataFrame and save\n",
    "                        df = pd.DataFrame(table_data)\n",
    "                        base_name = os.path.splitext(filename)[0]\n",
    "                        excel_filename = f\"{base_name}_table_{i+1}.xlsx\"\n",
    "                        output_path = os.path.join(output_folder, excel_filename)\n",
    "                        df.to_excel(output_path, index=False)\n",
    "                    \n",
    "                    successful.append(filename)\n",
    "                    logger.info(f\"Successfully extracted {len(table_blocks)} tables from {filename}\")\n",
    "                else:\n",
    "                    failed.append((filename, \"No tables found\"))\n",
    "                    logger.warning(f\"No tables found in {filename}\")\n",
    "            else:\n",
    "                failed.append((filename, \"No blocks in response\"))\n",
    "                logger.warning(f\"No blocks found in response for {filename}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error processing {filename}: {str(e)}\")\n",
    "            failed.append((filename, str(e)))\n",
    "    \n",
    "    # Print summary\n",
    "    logger.info(\"\\nProcessing complete!\")\n",
    "    logger.info(f\"Successfully processed: {len(successful)} images\")\n",
    "    logger.info(f\"Total tables extracted: {tables_found}\")\n",
    "    if failed:\n",
    "        logger.error(f\"\\nFailed to process {len(failed)} images:\")\n",
    "        for filename, error in failed:\n",
    "            logger.error(f\"- {filename}: {error}\")\n",
    "\n",
    "    return successful, failed, tables_found\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "774976e5-632a-407e-bb5c-09a6bcf3cbc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:   0%|                                                                         | 0/47 [00:00<?, ?it/s]WARNING:__main__:No tables found in 1920 Census_1.png\n",
      "Processing images:   2%|█▍                                                               | 1/47 [00:04<03:21,  4.38s/it]ERROR:__main__:Error processing 1920 Census_10.png: max() arg is an empty sequence\n",
      "Processing images:   4%|██▊                                                              | 2/47 [00:11<04:17,  5.73s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m extractor \u001b[38;5;241m=\u001b[39m Textractor(profile_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m successful, failed, tables \u001b[38;5;241m=\u001b[39m \u001b[43mbatch_resize_and_extract\u001b[49m\u001b[43m(\u001b[49m\u001b[43mextractor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_folder\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[10], line 66\u001b[0m, in \u001b[0;36mbatch_resize_and_extract\u001b[0;34m(extractor, input_folder, output_folder, max_size)\u001b[0m\n\u001b[1;32m     62\u001b[0m input_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(input_folder, filename)\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Image\u001b[38;5;241m.\u001b[39mopen(input_path) \u001b[38;5;28;01mas\u001b[39;00m img:\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;66;03m# Resize if needed\u001b[39;00m\n\u001b[0;32m---> 66\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43mresize_image_if_needed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# Convert to RGB if needed\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m img\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRGB\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "Cell \u001b[0;32mIn[6], line 20\u001b[0m, in \u001b[0;36mresize_image_if_needed\u001b[0;34m(img, max_size, quality)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Use LANCZOS for better quality, but fall back to NEAREST if memory error\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 20\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_width\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_height\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLANCZOS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mMemoryError\u001b[39;00m:\n\u001b[1;32m     22\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMemory error with LANCZOS, falling back to NEAREST\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/python_work/lib/python3.9/site-packages/PIL/Image.py:2345\u001b[0m, in \u001b[0;36mImage.resize\u001b[0;34m(self, size, resample, box, reducing_gap)\u001b[0m\n\u001b[1;32m   2342\u001b[0m     im \u001b[38;5;241m=\u001b[39m im\u001b[38;5;241m.\u001b[39mresize(size, resample, box)\n\u001b[1;32m   2343\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m im\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode)\n\u001b[0;32m-> 2345\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reducing_gap \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m resample \u001b[38;5;241m!=\u001b[39m Resampling\u001b[38;5;241m.\u001b[39mNEAREST:\n\u001b[1;32m   2348\u001b[0m     factor_x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m((box[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m-\u001b[39m box[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m/\u001b[39m size[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m/\u001b[39m reducing_gap) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/python_work/lib/python3.9/site-packages/PIL/ImageFile.py:300\u001b[0m, in \u001b[0;36mImageFile.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    297\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(msg)\n\u001b[1;32m    299\u001b[0m b \u001b[38;5;241m=\u001b[39m b \u001b[38;5;241m+\u001b[39m s\n\u001b[0;32m--> 300\u001b[0m n, err_code \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    302\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "extractor = Textractor(profile_name=\"default\")\n",
    "successful, failed, tables = batch_resize_and_extract(extractor, input_folder, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422b07b5-5c05-4062-8536-0c0f29f9dc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_files = [f for f in os.listdir(input_folder) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "test_image = image_files[20]\n",
    "debug_response = debug_textract_response(test_image, input_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "079a9064-3330-45cf-a230-0182f7f9ef1c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image: 1920 Census_27.png\n",
      "Original image size: (10176, 13184)\n",
      "\n",
      "Processing left half...\n",
      "Resizing to: 3048 x 7900\n",
      "Image size in bytes: 5,291,697\n",
      "Calling Textract...\n",
      "Total blocks found: 2179\n",
      "Total cells found: 797\n",
      "Found 102 distinct rows\n",
      "Saved table to: 1920 Census_27_left_table.xlsx\n",
      "\n",
      "Processing right half...\n",
      "Resizing to: 3048 x 7900\n",
      "Image size in bytes: 4,571,282\n",
      "Calling Textract...\n",
      "Total blocks found: 2042\n",
      "Total cells found: 685\n",
      "Found 85 distinct rows\n",
      "Saved table to: 1920 Census_27_right_table.xlsx\n"
     ]
    }
   ],
   "source": [
    "def split_and_process_census(input_folder, output_folder, image_index=19):\n",
    "    \"\"\"Split census page into left and right halves, then process each separately\"\"\"\n",
    "    image_files = [f for f in os.listdir(input_folder) \n",
    "                  if f.lower().endswith(('.png', '.jpg', '.jpeg', '.tiff', '.bmp'))]\n",
    "    \n",
    "    if not image_files:\n",
    "        print(\"No image files found in the input folder\")\n",
    "        return\n",
    "    \n",
    "    if image_index >= len(image_files):\n",
    "        print(f\"Image index {image_index + 1} is out of range. Only {len(image_files)} images in folder.\")\n",
    "        return\n",
    "        \n",
    "    filename = image_files[image_index]\n",
    "    print(f\"\\nProcessing image: {filename}\")\n",
    "    \n",
    "    try:\n",
    "        # Open and process the image\n",
    "        input_path = os.path.join(input_folder, filename)\n",
    "        with Image.open(input_path) as img:\n",
    "            print(f\"Original image size: {img.size}\")\n",
    "            \n",
    "            # Convert to RGB if needed\n",
    "            if img.mode != 'RGB':\n",
    "                img = img.convert('RGB')\n",
    "            \n",
    "            # Split image into left and right halves\n",
    "            width, height = img.size\n",
    "            mid_point = width // 2\n",
    "            \n",
    "            # Create left and right halves\n",
    "            left_half = img.crop((0, 0, mid_point, height))\n",
    "            right_half = img.crop((mid_point, 0, width, height))\n",
    "            \n",
    "            print(\"\\nProcessing left half...\")\n",
    "            process_half(left_half, filename, \"_left\", output_folder)\n",
    "            \n",
    "            print(\"\\nProcessing right half...\")\n",
    "            process_half(right_half, filename, \"_right\", output_folder)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing image: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "def process_half(img_half, original_filename, suffix, output_folder):\n",
    "    \"\"\"Process one half of the split census page\"\"\"\n",
    "    try:\n",
    "        # Resize if needed\n",
    "        max_dimension = 7900\n",
    "        width, height = img_half.size\n",
    "        resize_ratio = min(max_dimension / width, max_dimension / height)\n",
    "        \n",
    "        if resize_ratio < 1:\n",
    "            new_width = int(width * resize_ratio)\n",
    "            new_height = int(height * resize_ratio)\n",
    "            print(f\"Resizing to: {new_width} x {new_height}\")\n",
    "            img_half = img_half.resize((new_width, new_height), Image.Resampling.LANCZOS)\n",
    "        \n",
    "        # Convert to bytes\n",
    "        buffer = io.BytesIO()\n",
    "        quality = 95\n",
    "        while True:\n",
    "            buffer.seek(0)\n",
    "            buffer.truncate()\n",
    "            img_half.save(buffer, format='JPEG', quality=quality)\n",
    "            if buffer.tell() > 9.5 * 1024 * 1024:\n",
    "                quality -= 5\n",
    "                print(f\"Reducing quality to {quality}\")\n",
    "                if quality < 65:\n",
    "                    raise Exception(\"Cannot reduce image size enough while maintaining quality\")\n",
    "            else:\n",
    "                break\n",
    "        \n",
    "        image_bytes = buffer.getvalue()\n",
    "        print(f\"Image size in bytes: {len(image_bytes):,}\")\n",
    "        \n",
    "        # Call Textract\n",
    "        print(\"Calling Textract...\")\n",
    "        textract_client = boto3.client('textract')\n",
    "        response = textract_client.analyze_document(\n",
    "            Document={'Bytes': image_bytes},\n",
    "            FeatureTypes=['TABLES', 'FORMS']\n",
    "        )\n",
    "        \n",
    "        blocks = response['Blocks']\n",
    "        print(f\"Total blocks found: {len(blocks)}\")\n",
    "        \n",
    "        # Get all cells\n",
    "        all_cells = [block for block in blocks if block['BlockType'] in ['CELL', 'MERGED_CELL']]\n",
    "        print(f\"Total cells found: {len(all_cells)}\")\n",
    "        \n",
    "        if not all_cells:\n",
    "            print(\"No cells found!\")\n",
    "            return\n",
    "        \n",
    "        # Get cell positions\n",
    "        cell_tops = []\n",
    "        for cell in all_cells:\n",
    "            top = round(cell['Geometry']['BoundingBox']['Top'], 3)\n",
    "            grouped = False\n",
    "            for i, existing_top in enumerate(cell_tops):\n",
    "                if abs(top - existing_top) < 0.005:\n",
    "                    top = existing_top\n",
    "                    grouped = True\n",
    "                    break\n",
    "            if not grouped:\n",
    "                cell_tops.append(top)\n",
    "        \n",
    "        cell_tops = sorted(set(cell_tops))\n",
    "        print(f\"Found {len(cell_tops)} distinct rows\")\n",
    "        \n",
    "        # Group cells by row\n",
    "        rows = []\n",
    "        for top in cell_tops:\n",
    "            row_cells = [cell for cell in all_cells \n",
    "                        if abs(cell['Geometry']['BoundingBox']['Top'] - top) < 0.005]\n",
    "            if row_cells:\n",
    "                row_cells.sort(key=lambda c: c['Geometry']['BoundingBox']['Left'])\n",
    "                rows.append(row_cells)\n",
    "        \n",
    "        # Create table data\n",
    "        table_data = []\n",
    "        for row in rows:\n",
    "            row_data = []\n",
    "            for cell in row:\n",
    "                text = cell.get('Text', '')\n",
    "                if not text and 'Relationships' in cell:\n",
    "                    child_ids = [rel['Ids'] for rel in cell['Relationships'] \n",
    "                               if rel['Type'] == 'CHILD']\n",
    "                    if child_ids:\n",
    "                        child_texts = []\n",
    "                        for child_id_list in child_ids:\n",
    "                            for child_id in child_id_list:\n",
    "                                child_block = next((b for b in blocks if b['Id'] == child_id), None)\n",
    "                                if child_block and 'Text' in child_block:\n",
    "                                    child_texts.append(child_block['Text'])\n",
    "                        text = ' '.join(child_texts)\n",
    "                row_data.append(text)\n",
    "            table_data.append(row_data)\n",
    "        \n",
    "        # Pad rows to equal length\n",
    "        max_cols = max(len(row) for row in table_data)\n",
    "        table_data = [row + [''] * (max_cols - len(row)) for row in table_data]\n",
    "        \n",
    "        # Save to Excel\n",
    "        df = pd.DataFrame(table_data)\n",
    "        base_name = os.path.splitext(original_filename)[0]\n",
    "        excel_filename = f\"{base_name}{suffix}_table.xlsx\"\n",
    "        output_path = os.path.join(output_folder, excel_filename)\n",
    "        df.to_excel(output_path, index=False)\n",
    "        print(f\"Saved table to: {excel_filename}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing half: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "# Run the function\n",
    "split_and_process_census(input_folder, output_folder, 19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ee7d74-5383-4f85-a916-a0c856cc3ec9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
