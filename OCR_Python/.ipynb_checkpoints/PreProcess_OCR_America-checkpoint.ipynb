{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d96ca7c",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In this notebook, we use Amazon Textract and Google Vision to provide a quick way of extracting text/tables from an image of a page.\n",
    "\n",
    "Intended use: The intended use of this notebook is to quickly prototype. You should expect to modify the code in this notebook to suit your usecase.\n",
    "\n",
    "Preparation: At a minimum, set a working folder, and make sure to add your API keys for both Textract and Google Vision. To do so, please follow the steps outlined here: https://github.com/MikeJGiordano/OCR_History/blob/main/ReadMe.md\n",
    "\n",
    "This notebook contains four parts:\n",
    "\n",
    "    1. Unmodified image OCR. This is intended to quickly detect text from a single image.\n",
    "        a. There is then an option to run one or both OCR tools on a whole folder.\n",
    "        \n",
    "    2. Image preprocessing. This routine helps you to quickly preprocess a single image (adjust contrast, split image, etc). \n",
    "        a. If you are satisfied with the preprocessing routine, it will give you the option to preprocess a whole folder.\n",
    "        \n",
    "    3. Image preprocessing with text extraction. This runs the image modification from part 2 into the text detection from part 1.\n",
    "    \n",
    "    4. Image preprocessing with table extraction from Textract. This uses the image modification from part 2 to extract a table using Textract."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17f3fe1",
   "metadata": {},
   "source": [
    "# Program Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2655be",
   "metadata": {},
   "source": [
    "## There are 5 steps, marked A-E."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c497df2",
   "metadata": {},
   "source": [
    "### A: Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af15c6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import json\n",
    "import os\n",
    "\n",
    "# if you don't have these packages use any package manager to install\n",
    "# you can install all packages at once using the provided requirements.txt file\n",
    "import cv2\n",
    "import boto3\n",
    "from google.cloud import vision\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm as tq\n",
    "\n",
    "from PIL import Image, ImageDraw\n",
    "from textractor import Textractor\n",
    "from textractor.visualizers.entitylist import EntityList\n",
    "from textractor.data.constants import TextractFeatures, Direction, DirectionalFinderType\n",
    "import math \n",
    "\n",
    "# note: the following py file, you'll have to download\n",
    "import preprocess as pp \n",
    "import logging\n",
    "import sys\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "                   format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Disable PIL max image size limit\n",
    "Image.MAX_IMAGE_PIXELS = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7098cf",
   "metadata": {},
   "source": [
    "### B: Please set your working directories here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02996d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# please set the path to the folder containing your images here\n",
    "input_folder = \"/mnt/c/Users/WATLINGS/Documents/OCR Files/Census Processing/Documents/1920/Output\"\n",
    "output_folder = \"/mnt/c/Users/WATLINGS/Documents/OCR Files/Census Processing/Documents/1920/Output_OCR\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9adfe73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Authenticate Google Cloud here\n",
    "\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = '/mnt/c/Users/WATLINGS/Documents/GitHub/OCR_History/OCR_Python/ServiceAccountToken.json'\n",
    "client = vision.ImageAnnotatorClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a658deca",
   "metadata": {},
   "source": [
    "### E: Please authenticate Amazon Textract\n",
    "\n",
    "For help with Amazon Textract, see https://github.com/MikeJGiordano/OCR_History/blob/main/Setup_AWS_Root.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6044585",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Authenticate AWS Textract in the console/terminal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4334c36",
   "metadata": {},
   "source": [
    "# Part 1: Basic text extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c99c29a-b52e-4994-8604-d58572d83c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def resize_image_if_needed(img, max_size=8000, quality=85):\n",
    "    \"\"\"\n",
    "    Resize image if either dimension exceeds max_size while maintaining aspect ratio.\n",
    "    Added memory-efficient handling of large images.\n",
    "    \"\"\"\n",
    "    width, height = img.size\n",
    "    logger.info(f\"Processing image of size {width}x{height}\")\n",
    "    \n",
    "    if width > max_size or height > max_size:\n",
    "        # Calculate new dimensions\n",
    "        scale = max_size / max(width, height)\n",
    "        new_width = math.floor(width * scale)\n",
    "        new_height = math.floor(height * scale)\n",
    "        \n",
    "        try:\n",
    "            logger.info(f\"Resizing image from {width}x{height} to {new_width}x{new_height}\")\n",
    "            \n",
    "            # Use LANCZOS for better quality, but fall back to NEAREST if memory error\n",
    "            try:\n",
    "                img = img.resize((new_width, new_height), Image.LANCZOS)\n",
    "            except MemoryError:\n",
    "                logger.warning(\"Memory error with LANCZOS, falling back to NEAREST\")\n",
    "                img = img.resize((new_width, new_height), Image.NEAREST)\n",
    "            \n",
    "            logger.info(\"Resize successful\")\n",
    "            \n",
    "            # Convert to RGB if needed\n",
    "            if img.mode != 'RGB':\n",
    "                img = img.convert('RGB')\n",
    "                logger.info(\"Converted to RGB mode\")\n",
    "            \n",
    "            # Optimize memory usage\n",
    "            if max(new_width, new_height) > 4000:\n",
    "                # For very large images, compress more aggressively\n",
    "                quality = min(quality, 75)\n",
    "                logger.info(f\"Large image detected, using reduced quality: {quality}\")\n",
    "            \n",
    "            return img\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error during resize: {str(e)}\")\n",
    "            raise\n",
    "    \n",
    "    return img\n",
    "\n",
    "# First, let's create a function to process images and save results\n",
    "def process_and_save_text(input_folder, output_folder, filename):\n",
    "    print(f\"\\nProcessing {filename}...\")\n",
    "    \n",
    "    # Setup paths\n",
    "    input_path = os.path.join(input_folder, filename)\n",
    "    base_name = os.path.splitext(filename)[0]\n",
    "    output_text = os.path.join(output_folder, f\"{base_name}_Textract.txt\")\n",
    "    output_json = os.path.join(output_folder, f\"{base_name}_Textract.json\")\n",
    "    \n",
    "    try:\n",
    "        # Process image\n",
    "        with Image.open(input_path) as img:\n",
    "            # Resize if needed\n",
    "            img = resize_image_if_needed(img)\n",
    "            # Convert to RGB mode if needed\n",
    "            if img.mode != 'RGB':\n",
    "                img = img.convert('RGB')\n",
    "            # Save as JPEG in memory\n",
    "            buffer = io.BytesIO()\n",
    "            img.save(buffer, format='JPEG', quality=95)\n",
    "            image_content = buffer.getvalue()\n",
    "        \n",
    "        # Process with Textract\n",
    "        textract = boto3.client('textract')\n",
    "        response = textract.detect_document_text(\n",
    "            Document={'Bytes': image_content}\n",
    "        )\n",
    "        \n",
    "        # Save JSON response\n",
    "        with open(output_json, 'w', encoding='utf-8') as f:\n",
    "            json.dump(response, f, indent=2)\n",
    "            \n",
    "        # Save extracted text\n",
    "        with open(output_text, 'w', encoding='utf-8') as f:\n",
    "            for block in response['Blocks']:\n",
    "                if block['BlockType'] == 'LINE':\n",
    "                    f.write(block.get('Text', '') + '\\n')\n",
    "        \n",
    "        print(f\"Successfully processed {filename}\")\n",
    "        print(f\"Text saved to: {output_text}\")\n",
    "        print(f\"JSON saved to: {output_json}\")\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {filename}: {e}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cultural-glossary",
   "metadata": {},
   "source": [
    "# Part 2: Preprocess images\n",
    "Often, it helps to preprocess an image. Common routines are:\n",
    "    \n",
    "    1. Adjusting contrast or brightness\n",
    "    2. Converting to grayscale\n",
    "    3. Cropping\n",
    "    4. Erasing margins\n",
    "    5. Splitting images\n",
    "    \n",
    "We now provide two examples:\n",
    "    \n",
    "    1. Applying points 1-4 \n",
    "    2. Preprocessing and splitting the image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b9a192",
   "metadata": {},
   "source": [
    "### Example 1: Full image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "running-latvia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the filename to your image here\n",
    "railroad_table = \"1888_Page_161.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2976260b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The next cell will apply the default preprocess settings to your image.\n",
    "#If you are unsatisfied with those settings, it will instruct you on how to make changes.\n",
    "#Those changes should be inserted in this cell.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba78acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocess a single image.\n",
    "pp.preprocess_image(railroad_table,\n",
    "                       input_folder,\n",
    "                       output_folder,\n",
    "                       **pp.default);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5c663b",
   "metadata": {},
   "source": [
    "### Example 2: Split image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f8a707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the filename to your split image here\n",
    "korean_image = \"126.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ed09c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The next cell will apply the default preprocess settings to your image.\n",
    "#If you are unsatisfied with those settings, it will provide instructions on how to make changes.\n",
    "\n",
    "pp.default['left_margin_percent'] = 30\n",
    "pp.default['top_margin_percent'] = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26302043",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocess a split image.\n",
    "pp.preprocess_image(korean_image,\n",
    "                       input_folder,\n",
    "                       output_folder,\n",
    "                       **pp.default);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ea7b20",
   "metadata": {},
   "source": [
    "# Part 3: Preprocessed Text Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba520df",
   "metadata": {},
   "source": [
    "### Example 1: Full image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1450d027",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the above processing, the folder of modified images is located at:\n",
    "\n",
    "modified_images = \"output/modified_images/\"\n",
    "\n",
    "# Modification alters the name of the file to be:\n",
    "\n",
    "modified_railroad = 'modified_' + railroad_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f58288",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the image, save .json outputs\n",
    "pp.process_content(modified_railroad, \n",
    "                   modified_images,\n",
    "                   output_folder,\n",
    "                   show_image = True,\n",
    "                   use_google_vision=False, \n",
    "                   use_textract=True, \n",
    "                   verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2a4778",
   "metadata": {},
   "source": [
    "### Example 2: Split image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76c0e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modification splits the file into two and renames them:\n",
    "\n",
    "modified_1_split = 'modified_1_' + korean_image\n",
    "modified_2_split = 'modified_2_' + korean_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300ac7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the images, save .json and .txt outputs\n",
    "pp.process_content(modified_1_split, \n",
    "                   modified_images,\n",
    "                   output_folder,\n",
    "                   show_image = True,\n",
    "                   use_google_vision=True, \n",
    "                   use_textract=False, \n",
    "                   verbose=True)\n",
    "\n",
    "pp.process_content(modified_2_split, \n",
    "                   modified_images,\n",
    "                   output_folder,\n",
    "                   show_image = False,\n",
    "                   use_google_vision=False, \n",
    "                   use_textract=False, \n",
    "                   verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ddbd16",
   "metadata": {},
   "source": [
    "### You can use the next cell to get text and JSON files for the entire folder of modified images through Google Vision, Textract, or both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfff978",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch process all images in the modified folder, save .json outputs to the output folder\n",
    "\n",
    "pp.batch_ocr(modified_images, \n",
    "                 output_folder, \n",
    "                 use_google_vision=False, \n",
    "                 use_textract=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42bdc2f2",
   "metadata": {},
   "source": [
    "# Part 4: Textract Table Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e55ea7",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8cb3f4",
   "metadata": {},
   "source": [
    "Initialize Textractor client, modify region if required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594a17c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor = Textractor(profile_name=\"default\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6aa52b",
   "metadata": {},
   "source": [
    "Please specify the image you want to extract a table from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8150da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the above processing, the folder of modified images is located at:\n",
    "\n",
    "modified_images = \"output/modified_images/\"\n",
    "\n",
    "# Modification alters the name of the file to be:\n",
    "\n",
    "file_name = \"Volume 1. Population, General Report and Analysis_8.png\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce277761",
   "metadata": {},
   "source": [
    "## Extract the tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1dddf6-46fb-4b0a-bc77-a3f2329dcd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import math\n",
    "import io\n",
    "from tqdm import tqdm \n",
    "\n",
    "def process_image(input_path, max_size=8000):\n",
    "    \"\"\"Process a single image with enhanced error handling and memory management\"\"\"\n",
    "    try:\n",
    "        logger.info(f\"Opening image: {input_path}\")\n",
    "        \n",
    "        # Open image with lazy loading\n",
    "        with Image.open(input_path) as img:\n",
    "            # Get original size\n",
    "            orig_size = img.size\n",
    "            logger.info(f\"Original image size: {orig_size}, Mode: {img.mode}\")\n",
    "            \n",
    "            # Resize if needed\n",
    "            img = resize_image_if_needed(img, max_size)\n",
    "            \n",
    "            # Convert to RGB if needed\n",
    "            if img.mode != 'RGB':\n",
    "                img = img.convert('RGB')\n",
    "            \n",
    "            # Save as JPEG in memory with appropriate quality\n",
    "            buffer = io.BytesIO()\n",
    "            quality = 85 if max(img.size) <= 4000 else 75\n",
    "            img.save(buffer, format='JPEG', quality=quality, optimize=True)\n",
    "            \n",
    "            logger.info(f\"Successfully processed image. Original size: {orig_size}, Final size: {img.size}\")\n",
    "            return buffer.getvalue()\n",
    "            \n",
    "    except MemoryError:\n",
    "        logger.error(f\"Memory error processing {input_path}. Try reducing max_size parameter.\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error processing image {input_path}: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "def batch_resize_and_extract(extractor, input_folder, output_folder, max_size=8000):\n",
    "    \"\"\"Process all images in a folder with enhanced error handling\"\"\"\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    \n",
    "    # Get list of image files\n",
    "    valid_extensions = ['.jpg', '.jpeg', '.png', '.gif', '.tiff', '.bmp']\n",
    "    image_files = [f for f in os.listdir(input_folder) \n",
    "                  if any(f.lower().endswith(ext) for ext in valid_extensions)]\n",
    "    \n",
    "    if not image_files:\n",
    "        logger.warning(f\"No image files found in {input_folder}\")\n",
    "        return\n",
    "    \n",
    "    logger.info(f\"\\nProcessing {len(image_files)} images...\")\n",
    "    \n",
    "    successful = []\n",
    "    failed = []\n",
    "    tables_found = 0\n",
    "    \n",
    "    for filename in tqdm(image_files, desc=\"Processing images\"):\n",
    "        try:\n",
    "            # Process image first\n",
    "            input_path = os.path.join(input_folder, filename)\n",
    "            image_content = process_image(input_path, max_size)\n",
    "            \n",
    "            # Extract tables using Textract\n",
    "            document = extractor.analyze_document(\n",
    "                file_source=image_content,\n",
    "                features=[TextractFeatures.TABLES],\n",
    "                save_image=True\n",
    "            )\n",
    "            \n",
    "            if document and document.tables:\n",
    "                tables_found += len(document.tables)\n",
    "                # Save each table\n",
    "                for i, table in enumerate(document.tables):\n",
    "                    base_name = os.path.splitext(filename)[0]\n",
    "                    excel_filename = f\"{base_name}_table_{i+1}.xlsx\"\n",
    "                    output_path = os.path.join(output_folder, excel_filename)\n",
    "                    table.to_excel(output_path)\n",
    "                successful.append(filename)\n",
    "                logger.info(f\"Successfully extracted {len(document.tables)} tables from {filename}\")\n",
    "            else:\n",
    "                failed.append((filename, \"No tables found\"))\n",
    "                logger.warning(f\"No tables found in {filename}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error processing {filename}: {str(e)}\")\n",
    "            failed.append((filename, str(e)))\n",
    "    \n",
    "    # Print summary\n",
    "    logger.info(\"\\nProcessing complete!\")\n",
    "    logger.info(f\"Successfully processed: {len(successful)} images\")\n",
    "    logger.info(f\"Total tables extracted: {tables_found}\")\n",
    "    if failed:\n",
    "        logger.error(f\"\\nFailed to process {len(failed)} images:\")\n",
    "        for filename, error in failed:\n",
    "            logger.error(f\"- {filename}: {error}\")\n",
    "\n",
    "    return successful, failed, tables_found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774976e5-632a-407e-bb5c-09a6bcf3cbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor = Textractor(profile_name=\"default\")\n",
    "successful, failed, tables = batch_resize_and_extract(extractor, input_folder, output_folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
